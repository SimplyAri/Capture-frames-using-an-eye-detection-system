{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06cd053-a9ff-425a-8a58-15530b7d5df0",
   "metadata": {},
   "source": [
    "# Importing all the dependicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5026bd7f-98b8-46d0-b814-44ddcd009250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f21e00-8a7f-43e0-9d24-5ab66dffa2a5",
   "metadata": {},
   "source": [
    "# Defining a function for calculating an aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ec5559-4eb2-4b67-a033-70998579f9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    \n",
    "    vertical_val1 = dist.euclidean(eye[1], eye[5])\n",
    "    vertical_val2 = dist.euclidean(eye[2], eye[4])\n",
    "    \n",
    "    horizontal_val = dist.euclidean(eye[0], eye[3])\n",
    "    \n",
    "    ear= (vertical_val1 + vertical_val2)/(2*horizontal_val)\n",
    "    \n",
    "    return ear "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a35de-feb0-4bfa-a628-e85419994cfc",
   "metadata": {},
   "source": [
    "# Constants used to compare with and detect if a blink was detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2db2c1c-fab3-4c07-b63b-ac91a1473424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EAR_THRESH = 0.3\n",
    "EAR_CONSEC_FRAMES = 2\n",
    "TOTAL = 0\n",
    "COUNTER = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd21d58-d2b9-4d61-b41c-72e0d11d1396",
   "metadata": {},
   "source": [
    "# Setting out the models for detecting the face and predicting the facial landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19f6f0b8-89ec-4f7f-8113-df8c3d191dba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading facial landmark predictor...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('Model/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87403e9-bd83-4552-afc7-234845a24775",
   "metadata": {},
   "source": [
    "# Getting the face landmarks according the dlibs indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfeed75-b813-4cf2-a558-c3bf5e0363a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(lefteye_start,lefteye_end) = face_utils.FACIAL_LANDMARKS_IDXS['left_eye']\n",
    "(righteye_start,righteye_end) = face_utils.FACIAL_LANDMARKS_IDXS['right_eye']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164bc087-c17a-4d81-9401-109b9d7cadaf",
   "metadata": {},
   "source": [
    "# Generating a name for the saved file, carrying the detectiong and rendering out box accoringly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7b97a78-79cf-44ae-b970-50d206d42bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMGNAME= os.path.join(os.path.join('save'), f'{str(uuid.uuid1())}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54530aaf-7d49-43a4-92d6-a13cd85bd19b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7872a34-f019-4ef9-9f06-a1d63f2022e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n",
      "Counter: 4\n",
      "total: 1\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n",
      "Counter: 4\n",
      "total: 2\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n",
      "total: 3\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "total: 4\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "total: 5\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n",
      "Counter: 4\n",
      "Counter: 5\n",
      "Counter: 6\n",
      "total: 6\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n",
      "Counter: 4\n",
      "Counter: 5\n",
      "Counter: 6\n",
      "Counter: 7\n",
      "Counter: 8\n",
      "total: 7\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n",
      "Counter: 4\n",
      "Counter: 5\n",
      "Counter: 6\n",
      "total: 8\n",
      "Counter: 1\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "total: 9\n",
      "Counter: 1\n",
      "Counter: 2\n",
      "Counter: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "while True:\n",
    "    \n",
    "    _,frame = cam.read()\n",
    "    frame= imutils.resize(frame,450)\n",
    "    gray= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        leftEye = shape[lefteye_start:lefteye_end]\n",
    "        rightEye = shape[righteye_start:righteye_end]\n",
    "        leftEAR = eye_aspect_ratio(leftEye)\n",
    "        rightEAR = eye_aspect_ratio(rightEye)\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "\n",
    "        leftEyeHull = cv2.convexHull(leftEye)\n",
    "        rightEyeHull = cv2.convexHull(rightEye)\n",
    "        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
    "        cv2.drawContours(frame, [rightEyeHull],-1, (0, 255, 0), 1)\n",
    "        \n",
    "        if ear < EAR_THRESH:\n",
    "            COUNTER +=1\n",
    "            print('Counter:',COUNTER)\n",
    "        else:\n",
    "            if COUNTER >= EAR_CONSEC_FRAMES:\n",
    "                TOTAL +=1\n",
    "                cv2.imwrite(IMGNAME, frame)\n",
    "                print('total:',TOTAL)               \n",
    "            COUNTER = 0\n",
    "            \n",
    "            cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"EAR: {:.2f}\".format(ear), (300, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "                        \n",
    "    cv2.imshow('Frame', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "    if key == ord('q'):\n",
    "        break\n",
    "            \n",
    "cv2.destroyAllWindows()\n",
    "cam.release()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b08d5-2e61-47b9-851f-df170aec45c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eyedetec",
   "language": "python",
   "name": "eyedetec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
